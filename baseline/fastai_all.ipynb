{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastai.tabular import *\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import nvstrings\n",
    "import warnings\n",
    "import cudf as gd\n",
    "from numba import cuda\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_reciprocal_rank(sub):\n",
    "    # sub is a pandas dataframe\n",
    "    # sub should have the following columns:\n",
    "    # 'row_id', 'prob', 'reference', 'item_id'\n",
    "    # sorted by prob in descending order for each group\n",
    "    sub = gd.from_pandas(sub)\n",
    "    \n",
    "    def get_order_in_group(prob,row_id,order):\n",
    "        for i in range(cuda.threadIdx.x, len(prob), cuda.blockDim.x):\n",
    "            order[i] = i\n",
    "\n",
    "    dg = sub.groupby('row_id',method=\"cudf\").apply_grouped(get_order_in_group,incols=['prob','row_id'],\n",
    "                                  outcols={'order': np.int32},\n",
    "                                  tpb=32)\n",
    "\n",
    "    dg = dg.to_pandas()\n",
    "    dg['order'] = 1.0/(1+dg['order'])\n",
    "    dg = dg[dg['reference']==dg['item_id']]\n",
    "    return dg['order'].mean() \n",
    "\n",
    "def auroc_score(input, target):\n",
    "    input, target = input.cpu().numpy()[:,1], target.cpu().numpy()\n",
    "    return roc_auc_score(target, input)\n",
    "\n",
    "# Callback to calculate AUC at the end of each epoch\n",
    "class AUROC(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['AUROC'])\n",
    "    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []\n",
    "\n",
    "    def on_batch_end(self, last_target, last_output, train, **kwargs):\n",
    "        if not train:\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if len(self.output) > 0:\n",
    "            output = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            preds = F.softmax(output, dim=1)\n",
    "            metric = auroc_score(preds, target)\n",
    "            return add_metrics(last_metrics, [metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 16 s, total: 27.3 s\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_pair = pd.read_pickle('cache/data_pair_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42756036, 46) (5762533, 46)\n",
      "CPU times: user 8.12 s, sys: 8.92 s, total: 17 s\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = data_pair[data_pair.clickout_missing==0]\n",
    "test = data_pair[data_pair.clickout_missing>0]\n",
    "print(train.shape,test.shape)\n",
    "del data_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 123 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_names = ['user_id','item_id','platform','city','device','current_filters'] + [i for i in train.columns if i.startswith('is_')]\n",
    "cont_names = ['price','candidate_order','item_count'] + [i for i in train.columns if i.startswith('count') or 'rank' in i or i.startswith('delta_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 2min 36s, total: 5min 58s\n",
      "Wall time: 5min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "procs = [FillMissing, Categorify, Normalize]\n",
    "train['is_va'] = train.row_id%5 == 0\n",
    "\n",
    "test_list = TabularList.from_df(test, path='./', cat_names=cat_names, cont_names=cont_names)\n",
    "data = (TabularList.from_df(train, path='./', cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
    "                           .split_from_df('is_va')\n",
    "                           .label_from_df(cols='target')\n",
    "                           .add_test(test_list)\n",
    "                           .databunch(num_workers=8,bs=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.114635</td>\n",
       "      <td>0.113934</td>\n",
       "      <td>0.887146</td>\n",
       "      <td>13:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with AUROC value: 0.8871461408447601.\n",
      "CPU times: user 10min 51s, sys: 2min 50s, total: 13min 42s\n",
      "Wall time: 13min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = tabular_learner(data, layers=[64,32], metrics=None, callback_fns=AUROC,#wd=0.2,\n",
    "        emb_szs = {'user_id':16,'item_id':16,'platform':4,'city':8,'device':1,\n",
    "                   'current_filters':8, 'has_past': 1}\n",
    ")\n",
    "\n",
    "learn.fit_one_cycle(1, max_lr=slice(3e-3), callbacks=[SaveModelCallback(learn,\n",
    "        every='improvement', monitor='AUROC',name='tab_nn')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "yp,y_valid = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv = train.loc[train['is_va']>0,['row_id','reference','item_id']].copy()\n",
    "cv['prob'] = yp.numpy()[:,1]\n",
    "cv = cv.sort_values(by=['row_id','prob'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "auc = roc_auc_score(y_valid.numpy().ravel(),yp.numpy()[:,1])\n",
    "mean_reciprocal_rank = get_mean_reciprocal_rank(cv)\n",
    "print('mean_reciprocal_rank %.4f, AUC %.4f'%(mean_reciprocal_rank,auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "yps,_ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test['target'] = yps.numpy()[:,1]\n",
    "test = test['row_id,user_id,session_id,timestamp,step,item_id,target'.split(',')]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = test.sort_values(by=['row_id','target'],ascending=False) # larger probs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sub = test[['row_id','item_id']].copy()\n",
    "sub = sub.groupby('row_id')['item_id'].apply(lambda x: ' '.join([str(i) for i in x]))\n",
    "sub = sub.to_frame()\n",
    "sub.columns = ['new_item_recommendations']\n",
    "sub = sub.reset_index()\n",
    "\n",
    "test = test.drop_duplicates(subset=['row_id'])\n",
    "sub = test.merge(sub,on='row_id',how='left')\n",
    "sub = sub[['session_id','new_item_recommendations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#sample_sub = pd.read_csv('/datasets/trivago/data/submission_popular.csv')\n",
    "sample_sub = pd.read_csv('../input/submission_popular.csv')\n",
    "assert sample_sub.shape[0] == sample_sub.session_id.unique().shape[0]\n",
    "sub = sample_sub.merge(sub,on='session_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "clock = \"{}\".format(datetime.now()).replace(' ','-').replace(':','-').split('.')[0]\n",
    "\n",
    "mask = sub.new_item_recommendations.isnull() == 0\n",
    "sub.loc[mask,'item_recommendations'] = sub.loc[mask,'new_item_recommendations']\n",
    "sub = sub.drop('new_item_recommendations',axis=1)\n",
    "out = 'fastai_%s_mrr_%.4f_auc_%.4f.csv'%(clock,mean_reciprocal_rank,auc)\n",
    "sub.to_csv(out,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
