{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "import nvstrings\n",
    "import warnings\n",
    "import cudf as gd\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from datetime import date\n",
    "from fastai.callbacks import *\n",
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "from fastai.text import *\n",
    "from fastai.metrics import accuracy\n",
    "from multiprocessing import Process\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2> Functions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#                       #\n",
    "# Metrics and callbacks #\n",
    "#                       #\n",
    "#########################\n",
    "\n",
    "def write_pkl(obj, file_path=None):\n",
    "    if not file_path:\n",
    "        date_time = date.fromtimestamp(time.time()).strftime(\"%m_%d_%Y_%H-%M-%S\")\n",
    "        file_path=f'{date_time}.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_out = pickle.dumps(obj, protocol=4)\n",
    "    with open(file_path, 'wb') as f_out:\n",
    "        for idx in range(0, len(bytes_out), max_bytes):\n",
    "            f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "\n",
    "\n",
    "def get_mean_reciprocal_rank(sub):\n",
    "    # sub is a pandas dataframe\n",
    "    # sub should have the following columns:\n",
    "    # 'row_id', 'prob', 'reference', 'item_id'\n",
    "    # sorted by prob in descending order for each group\n",
    "    sub = gd.from_pandas(sub)\n",
    "    \n",
    "    def get_order_in_group(prob,row_id,order):\n",
    "        for i in range(cuda.threadIdx.x, len(prob), cuda.blockDim.x):\n",
    "            order[i] = i\n",
    "\n",
    "    dg = sub.groupby('row_id',method=\"cudf\").apply_grouped(get_order_in_group,incols=['prob','row_id'],\n",
    "                                  outcols={'order': np.int32},\n",
    "                                  tpb=32)\n",
    "\n",
    "    dg = dg.to_pandas()\n",
    "    dg['order'] = 1.0/(1+dg['order'])\n",
    "    dg = dg[dg['reference']==dg['item_id']]\n",
    "    print(dg.isnull().values.any())\n",
    "    return dg['order'].mean()\n",
    "\n",
    "def auroc_score(input, target):\n",
    "    input, target = input.cpu().numpy()[:,1], target.cpu().numpy()\n",
    "    return roc_auc_score(target, input)\n",
    "\n",
    "# Callback to calculate AUC at the end of each epoch\n",
    "class AUROC(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['AUROC'])\n",
    "    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []\n",
    "\n",
    "    def on_batch_end(self, last_target, last_output, train, **kwargs):\n",
    "        if not train:\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if len(self.output) > 0:\n",
    "            output = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            preds = F.softmax(output, dim=1)\n",
    "            metric = auroc_score(preds, target)\n",
    "            return add_metrics(last_metrics, [metric])\n",
    "\n",
    "        \n",
    "def get_idx(x): \n",
    "    return 0 if pd.isnull(x) else id_to_index.get(str(x), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Data Processing </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/id_to_index.pkl', 'rb') as handle:\n",
    "    id_to_index = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.1 s, sys: 31.5 s, total: 48.5 s\n",
      "Wall time: 51.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#load tabular data \n",
    "data_pair = pd.read_pickle('cache/data_pair_all.pkl')\n",
    "data_pair = data_pair.drop(columns = [c for c in data_pair.columns if c.startswith('delta') or c.startswith('is')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.25 s, sys: 1.61 s, total: 9.86 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_context = pd.read_csv('cache/context_info_multi_2_more.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickout_list = [c for c in data_context.columns if 'clickout_item' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      0,  109038, 1032816,   65685, ..., 5997900, 2633858,   99769, 2343502])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_context['past_clickout_item_0'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context[clickout_list ] = data_context[clickout_list].applymap(get_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 1min 23s, total: 2min 25s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_pair = data_pair.merge(data_context, on='row_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42756036, 89) (5762533, 89)\n"
     ]
    }
   ],
   "source": [
    "# get the train and test dataset \n",
    "train = data_pair[data_pair.clickout_missing==0]\n",
    "test = data_pair[data_pair.clickout_missing>0]\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['is_va'] = train.row_id%5 == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Input Data </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"clickout_available\", 'clickout_is_same', 'clickout_impression_valid',  \"has_changed_sort\", \n",
    "            \"sort_metric\"]\n",
    "cont_cols = [\"clickout_step_diff\", \"price\", \"clickout_timestamp_diff\", 'clickout_price_mean', 'clickout_price_std',\n",
    "            \"cur_item_interaction_image_count\",\"cur_item_interaction_info_count\", \"cur_item_interaction_deal_count\",\n",
    "            \"cur_item_interaction_rating_count\", \"clickout_count\", \"other_clicked_item_interaction_image_count\",\n",
    "            \"other_clicked_item_interaction_info_count\", \"other_clicked_item_interaction_deal_count\",\n",
    "            \"other_clicked_item_interaction_rating_count\", \"num_of_search_poi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 261 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "cat_names = ['user_id','item_id','platform','city','device','current_filters']\n",
    "cat_names += [c for c in data_pair.columns for sub in cat_cols if sub in c]\n",
    "\n",
    "cont_names = ['price','candidate_order','item_count'] + [i for i in train.columns if i.startswith('count') or 'rank' in i or i.startswith('delta_')]\n",
    "cont_names += [c for c in data_pair.columns for sub in cont_cols if sub in c]\n",
    "cont_names = list(set(cont_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'item_id',\n",
       " 'platform',\n",
       " 'city',\n",
       " 'device',\n",
       " 'current_filters',\n",
       " 'past_clickout_available_0',\n",
       " 'past_clickout_is_same_0',\n",
       " 'past_clickout_impression_valid_0',\n",
       " 'past_clickout_available_1',\n",
       " 'past_clickout_is_same_1',\n",
       " 'past_clickout_impression_valid_1',\n",
       " 'has_changed_sort_past',\n",
       " 'sort_metric_past',\n",
       " 'future_clickout_available_0',\n",
       " 'future_clickout_is_same_0',\n",
       " 'future_clickout_impression_valid_0',\n",
       " 'future_clickout_available_1',\n",
       " 'future_clickout_is_same_1',\n",
       " 'future_clickout_impression_valid_1',\n",
       " 'has_changed_sort_future',\n",
       " 'sort_metric_future']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price_rank_norm',\n",
       " 'future_clickout_timestamp_diff_1',\n",
       " 'other_clicked_item_interaction_rating_count_future',\n",
       " 'count_item_user_id_session_id_rank_norm',\n",
       " 'past_clickout_step_diff_1',\n",
       " 'cur_item_interaction_info_count_future',\n",
       " 'item_count',\n",
       " 'past_clickout_price_mean_1',\n",
       " 'cur_item_interaction_deal_count_future',\n",
       " 'num_of_search_poi_future',\n",
       " 'future_clickout_step_diff_0',\n",
       " 'count_item_user_id_session_id_rank',\n",
       " 'past_clickout_timestamp_diff_1',\n",
       " 'future_clickout_price_1',\n",
       " 'cur_item_interaction_image_count_past',\n",
       " 'future_clickout_timestamp_diff_0',\n",
       " 'other_clicked_item_interaction_deal_count_future',\n",
       " 'past_clickout_step_diff_0',\n",
       " 'past_clickout_price_0',\n",
       " 'count_item_user_id',\n",
       " 'count_item_user_id_session_id',\n",
       " 'cur_item_interaction_info_count_past',\n",
       " 'other_clicked_item_interaction_image_count_future',\n",
       " 'cur_item_interaction_deal_count_past',\n",
       " 'item_count_rank_norm',\n",
       " 'future_clickout_price_std_1',\n",
       " 'price_rank',\n",
       " 'other_clicked_item_interaction_deal_count_past',\n",
       " 'past_clickout_price_std_0',\n",
       " 'other_clicked_item_interaction_info_count_future',\n",
       " 'count_item_user_id_session_id_norm',\n",
       " 'count_item_user_id_rank_norm',\n",
       " 'past_clickout_timestamp_diff_0',\n",
       " 'other_clicked_item_interaction_image_count_past',\n",
       " 'future_clickout_price_0',\n",
       " 'future_clickout_price_mean_0',\n",
       " 'past_clickout_price_std_1',\n",
       " 'cur_item_interaction_image_count_future',\n",
       " 'cur_item_interaction_rating_count_future',\n",
       " 'num_of_search_poi_past',\n",
       " 'price',\n",
       " 'clickout_count_past',\n",
       " 'count_item_user_id_norm',\n",
       " 'item_count_rank',\n",
       " 'other_clicked_item_interaction_rating_count_past',\n",
       " 'cur_item_interaction_rating_count_past',\n",
       " 'past_clickout_price_1',\n",
       " 'candidate_order',\n",
       " 'count_item_user_id_rank',\n",
       " 'clickout_count_future',\n",
       " 'future_clickout_price_std_0',\n",
       " 'future_clickout_step_diff_1',\n",
       " 'other_clicked_item_interaction_info_count_past',\n",
       " 'future_clickout_price_mean_1',\n",
       " 'past_clickout_price_mean_0']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 35s, sys: 9min 35s, total: 16min 11s\n",
      "Wall time: 14min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "procs = [FillMissing, Categorify, Normalize]\n",
    "train['is_va'] = train.row_id%5 == 0\n",
    "\n",
    "test_list = TabularList.from_df(test, path='./', cat_names=cat_names, cont_names=cont_names)\n",
    "\n",
    "data_tab = (TabularList.from_df(train, path='./', cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
    "                           .split_from_df('is_va')\n",
    "                           .label_from_df(cols='target')\n",
    "                           .add_test(test_list)\n",
    "                           .databunch(num_workers=10,bs=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# write_pkl(data_tab, \"./data_tab_1.csv\")\n",
    "# del data_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# data_tab = pickle.load(open('data_tab_1.csv', 'rb'))\n",
    "# data_tab.batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.4 s, sys: 1.55 s, total: 7.95 s\n",
      "Wall time: 7.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = tabular_learner(data_tab, layers=[256, 128], metrics=None, callback_fns=AUROC,#wd=0.2,\n",
    "        emb_szs = {'user_id': 32,'item_id':32,'platform':4,'city':8,'device':1,\n",
    "                   'current_filters':8, 'searched_item_id_past': 32, 'searched_item_id_future': 32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.101920</td>\n",
       "      <td>0.103263</td>\n",
       "      <td>0.915998</td>\n",
       "      <td>13:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.097125</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>0.915720</td>\n",
       "      <td>13:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with AUROC value: 0.9159981114231803.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, max_lr=slice(1e-3), callbacks=[SaveModelCallback(learn,\n",
    "        every='improvement', monitor='AUROC',name='tab_nn')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Performance Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.7 s, sys: 48.8 s, total: 1min 29s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "yp,y_valid = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv = train.loc[train['row_id']%5 == 0,['row_id','reference','item_id', 'target']].copy()\n",
    "cv['prob'] = yp.numpy()[:,1]\n",
    "cv = cv.sort_values(by=['row_id','prob'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv['rank']=cv.groupby('row_id')['prob'].rank(ascending=False) \n",
    "target_rank = cv[cv['target']==1]['rank']\n",
    "target_rank.hist(bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "auc = roc_auc_score(y_valid.numpy().ravel(),yp.numpy()[:,1])\n",
    "mean_reciprocal_rank = (1/target_rank).mean() # get_mean_reciprocal_rank(cv)\n",
    "print('mean_reciprocal_rank %.4f, AUC %.4f'%(mean_reciprocal_rank,auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "yps,_ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test['target'] = yps.numpy()[:,1]\n",
    "test = test['row_id,user_id,session_id,timestamp,step,item_id,target'.split(',')]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = test.sort_values(by=['row_id','target'],ascending=False) # larger probs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sub = test[['row_id','item_id']].copy()\n",
    "sub = sub.groupby('row_id')['item_id'].apply(lambda x: ' '.join([str(i) for i in x]))\n",
    "sub = sub.to_frame()\n",
    "sub.columns = ['new_item_recommendations']\n",
    "sub = sub.reset_index()\n",
    "\n",
    "test = test.drop_duplicates(subset=['row_id'])\n",
    "sub = test.merge(sub,on='row_id',how='left')\n",
    "sub = sub[['session_id','new_item_recommendations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_sub = pd.read_csv('/datasets/trivago/data/submission_popular.csv')\n",
    "# sample_sub = pd.read_csv('../input/submission_popular.csv')\n",
    "assert sample_sub.shape[0] == sample_sub.session_id.unique().shape[0]\n",
    "sub = sample_sub.merge(sub,on='session_id',how='left')\n",
    "\n",
    "from datetime import datetime\n",
    "clock = \"{}\".format(datetime.now()).replace(' ','-').replace(':','-').split('.')[0]\n",
    "\n",
    "mask = sub.new_item_recommendations.isnull() == 0\n",
    "sub.loc[mask,'item_recommendations'] = sub.loc[mask,'new_item_recommendations']\n",
    "sub = sub.drop('new_item_recommendations',axis=1)\n",
    "out = 'fastai_%s_mrr_%.4f_auc_%.4f.csv'%(clock,mean_reciprocal_rank,auc)\n",
    "sub.to_csv(out,index=False)\n",
    "\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fastai_2019-06-30-06-32-46_mrr_0.6400_auc_0.9175.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('fastai_2019-06-28-22-53-15_mrr_0.1726_auc_0.9266.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
