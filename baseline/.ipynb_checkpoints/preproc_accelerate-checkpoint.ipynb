{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "import nvstrings, nvcategory\n",
    "import warnings\n",
    "import cudf\n",
    "import pyarrow.parquet as pq\n",
    "import pdb\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from fastai import *\n",
    "from fastai.basic_data import *\n",
    "from librmm_cffi import librmm\n",
    "from fastai_modified.core_cudf import *\n",
    "from time import time\n",
    "from torch import tensor\n",
    "from torch.utils import data as torch_data\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "from cuml.preprocessing import LabelEncoder\n",
    "from sys import getsizeof\n",
    "from numba import cuda\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from datetime import date\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "%reload_ext snakeviz\n",
    "GPU_id = 4\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIAN = \"median\"\n",
    "CONSTANT = \"constant\"\n",
    "TRAIN = 'train'\n",
    "VALID = 'valid'\n",
    "TEST = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <center> Pre processing </center> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _enforce_str(y: cudf.Series) -> cudf.Series:\n",
    "    \"\"\"\n",
    "    Ensure that nvcategory is being given strings\n",
    "    \"\"\"\n",
    "    if y.dtype != \"object\":\n",
    "        return y.astype(\"str\")\n",
    "    return y\n",
    "\n",
    "\n",
    "class MyLabelEncoder(object):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self._cats: nvcategory.nvcategory = None\n",
    "        self._dtype = None\n",
    "        self._fitted: bool = False\n",
    "\n",
    "    def _check_is_fitted(self):\n",
    "        if not self._fitted:\n",
    "            raise TypeError(\"Model must first be .fit()\")\n",
    "\n",
    "    def fit(self, y: cudf.Series) -> \"LabelEncoder\":\n",
    "        self._dtype = y.dtype\n",
    "\n",
    "        y = _enforce_str(y)\n",
    "\n",
    "        self._cats = nvcategory.from_strings(y.data)\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, y: cudf.Series) -> cudf.Series:\n",
    "        self._check_is_fitted()\n",
    "        y = _enforce_str(y)\n",
    "        encoded = cudf.Series(\n",
    "            nvcategory.from_strings(y.data)\n",
    "            .set_keys(self._cats.keys())\n",
    "            .values()\n",
    "        )\n",
    "        return encoded.replace(-1, 0)\n",
    "\n",
    "    def fit_transform(self, y: cudf.Series) -> cudf.Series:\n",
    "        self._dtype = y.dtype\n",
    "\n",
    "        # Convert y to nvstrings series, if it isn't one\n",
    "        y = _enforce_str(y)\n",
    "\n",
    "        # Bottleneck is here, despite everything being done on the device\n",
    "        self._cats = nvcategory.from_strings(y.data)\n",
    "\n",
    "        self._fitted = True\n",
    "        arr: librmm.device_array = librmm.device_array(\n",
    "            y.data.size(), dtype=np.int32\n",
    "        )\n",
    "        self._cats.values(devptr=arr.device_ctypes_pointer.value)\n",
    "        return cudf.Series(arr)\n",
    "\n",
    "    def inverse_transform(self, y: cudf.Series) -> cudf.Series:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingColByCol():\n",
    "    fill_strategy = MEDIAN\n",
    "    add_col = False\n",
    "    fill_val = 0\n",
    "    means, stds, filler, category_encoders, col_name_missing = {}, {}, {}, {}, set()\n",
    "\n",
    "    def __init__(self, path, cat_names, cont_names, label_name, fill_strategy=MEDIAN):\n",
    "        # path + name is the file\n",
    "        self.path = path\n",
    "        self.cat_names, self.cont_names, self.label_name = cat_names, cont_names, label_name\n",
    "        self.fill_strategy = fill_strategy\n",
    "\n",
    "    def preproc_dataframe(self, mode):\n",
    "        self.mode = mode\n",
    "        get_col = lambda n: cudf.read_parquet(f\"{self.path}/{mode}/{n}.parquet\")[n]\n",
    "        get_tensor = lambda col: from_dlpack(col.to_dlpack()).view(col.shape[0], -1).to(cpu)\n",
    "        cats, conts = [], []\n",
    "        for n in self.cat_names:\n",
    "            col = get_col(n)\n",
    "            col = self.categorify(col, n)\n",
    "            cats.append(get_tensor(col).long())\n",
    "        for n in self.cont_names:\n",
    "            col = get_col(n)\n",
    "            col = self.fill_missing(col, n)\n",
    "            col = self.normalize(col, n)\n",
    "            conts.append(get_tensor(col).float())\n",
    "        label = get_tensor(get_col(self.label_name)).float().squeeze(1)\n",
    "        return (torch.cat(cats, 1), torch.cat(conts, 1)), label\n",
    "\n",
    "    def normalize(self, col: cudf.Series, col_name):\n",
    "        if self.mode == TRAIN: self.means[col_name], self.stds[col_name] = col.mean(), col.std()\n",
    "        return (col - self.means[col_name]) / (1e-7 + self.stds[col_name])\n",
    "\n",
    "    def get_median(self, col: cudf.Series):\n",
    "        col = col.dropna().reset_index(drop=True).sort_values()\n",
    "        return col[len(col)//2]\n",
    "\n",
    "    def add_col_(self, col: cudf.Series, col_name):\n",
    "        col_name_na = col_name + \"_na\"\n",
    "        self.df[col_name_na] = col.isna().to_pandas().astype('int64')\n",
    "        if col_name_na not in self.cat_names: self.cat_names.append(col_name_na)\n",
    "\n",
    "    def fill_missing(self, col: cudf.Series, col_name):\n",
    "        if col.isna().sum() == 0: return col\n",
    "        if self.mode != TRAIN:\n",
    "            if col_name not in self.col_name_missing:\n",
    "                raise Exception(f\"\"\"There are nan values in field {col_name} but there were none in the training set. \n",
    "                Please fix those manually.\"\"\")\n",
    "        else:\n",
    "            self.col_name_missing.add(col_name)\n",
    "            if self.fill_strategy == MEDIAN:\n",
    "                self.filler[col_name] = self.get_median(col)\n",
    "            elif self.fill_strategy == CONSTANT:\n",
    "                self.filler[col_name] = self.fill_val\n",
    "            else:\n",
    "                self.filler[col_name] = col.value_counts().index[0]\n",
    "        if self.add_col: self.add_col_(col, col_name)\n",
    "        return col.fillna(self.filler[col_name])\n",
    "\n",
    "    def categorify(self, col: cudf.Series, col_name):\n",
    "        if self.mode != TRAIN: \n",
    "            result = self.category_encoders[col_name].transform(col.append([None]))[:-1]\n",
    "        else:\n",
    "            self.category_encoders[col_name] = MyLabelEncoder()\n",
    "            result = self.category_encoders[col_name].fit_transform(col.append([None]))[:-1]\n",
    "        return result.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessDF():\n",
    "    fill_strategy = MEDIAN\n",
    "    add_col = False\n",
    "    fill_val = 0\n",
    "    category_encoders = {}\n",
    "\n",
    "    def __init__(self, cat_names, cont_names, label_name, mode=TRAIN, fill_strategy=MEDIAN, to_cpu=True):\n",
    "        self.cat_names, self.cont_names = cat_names, cont_names\n",
    "        self.fill_strategy = fill_strategy\n",
    "        self.label_name = label_name\n",
    "        self.to_cpu = to_cpu \n",
    "\n",
    "    def preproc_dataframe(self, gdf: cudf.dataframe, mode):\n",
    "        self.gdf = gdf\n",
    "        self.mode = mode\n",
    "        self.categorify()\n",
    "        self.fill_missing()\n",
    "        self.normalize()\n",
    "        if is_listy(self.label_name): \n",
    "            for n in self.label_name: self.gdf[n] = self.gdf[n].astype('float32')\n",
    "        else: self.gdf[self.label_name] = self.gdf[self.label_name].astype('float32')\n",
    "        # int64 in cudf may not be equivalent to that in pytorch\n",
    "        cats = from_dlpack(self.gdf[self.cat_names].to_dlpack()).long()\n",
    "        conts = from_dlpack(self.gdf[self.cont_names].to_dlpack())\n",
    "        label = from_dlpack(self.gdf[self.label_name].to_dlpack())\n",
    "        if self.to_cpu: (cats, conts), label = (cats.to(cpu), conts.to(cpu)), label.to(cpu)\n",
    "        return (cats, conts), label\n",
    "\n",
    "    def normalize(self):\n",
    "        if self.mode == TRAIN:\n",
    "            self.means, self.stds = self.gdf[self.cont_names].mean(), self.gdf[self.cont_names].std()\n",
    "        for i, name in enumerate(self.cont_names):\n",
    "            self.gdf[name] = ((self.gdf[name]-self.means[i])/(1e-7+self.stds[i])).astype('float32')\n",
    "\n",
    "    def get_median(self, col: cudf.Series):\n",
    "        col = col.dropna().reset_index(drop=True).sort_values()\n",
    "        return col[len(col)//2]\n",
    "\n",
    "    def add_col_(self, cont_names_na):\n",
    "        for name in cont_names_na:\n",
    "            name_na = name + \"_na\"\n",
    "            self.gdf[name_na] = self.gdf[name].isna()\n",
    "            if name_na not in self.cat_names: self.cat_names.append(name_na)\n",
    "\n",
    "    def fill_missing(self):\n",
    "        if self.mode == TRAIN:\n",
    "            self.train_cont_names_na = [name for name in self.cont_names if self.gdf[name].isna().sum()]\n",
    "            if self.fill_strategy == MEDIAN:\n",
    "                self.filler = {name: self.get_median(self.gdf[name]) for name in self.train_cont_names_na}\n",
    "            elif self.fill_strategy == CONSTANT:\n",
    "                self.filler = {name: self.fill_val for name in self.train_cont_names_na}\n",
    "            else:\n",
    "                self.filler = {name: self.gdf[name].value_counts().index[0] for name in self.train_cont_names_na}\n",
    "            if self.add_col: \n",
    "                self.add_col_(self.train_cont_names_na)\n",
    "            self.gdf[self.train_cont_names_na].fillna(self.filler, inplace=True)\n",
    "        else:\n",
    "            cont_names_na = [name for name in self.cont_names if self.gdf[name].isna().sum()]\n",
    "            if not set(cont_names_na).issubset(set(self.train_cont_names_na)):\n",
    "                 raise Exception(f\"\"\"There are nan values in field {cont_names_na} but there were none in the training set. \n",
    "                 Please fix those manually.\"\"\")\n",
    "            if self.add_col: self.add_col_(cont_names_na)\n",
    "            self.gdf[self.train_cont_names_na].fillna(self.filler, inplace=True)\n",
    "\n",
    "    def categorify(self):\n",
    "        for name in self.cat_names:\n",
    "            if self.mode == TRAIN:\n",
    "                self.category_encoders[name] = MyLabelEncoder()\n",
    "                self.gdf[name] = self.category_encoders[name].fit_transform(self.gdf[name].append([None]))[:-1]\n",
    "            else: self.gdf[name] = self.category_encoders[name].transform(self.gdf[name].append([None]))[:-1]\n",
    "            self.gdf[name] = self.gdf[name].astype('int64')\n",
    "    \n",
    "    def get_emb_sz(self):\n",
    "        work_in = {}\n",
    "        for key, val in self.category_encoders.items():\n",
    "            work_in[key] = len(val._cats.keys()) + 1\n",
    "        ret_list = [self.def_emb_sz(work_in, n) for n in self.cat_names]\n",
    "        return ret_list\n",
    "        \n",
    "    def emb_sz_rule(self, n_cat:int)->int: return min(600, round(1.6 * n_cat**0.56))\n",
    "\n",
    "    def def_emb_sz(self, classes, n, sz_dict=None):\n",
    "        \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n",
    "        sz_dict = ifnone(sz_dict, {})\n",
    "        n_cat = classes[n]\n",
    "        sz = sz_dict.get(n, int(self.emb_sz_rule(n_cat)))  # rule of thumb\n",
    "        self.embed_sz[n] = sz\n",
    "        return n_cat,sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train = cudf.read_parquet('train.parquet')\n",
    "# test = cudf.read_parquet('test.parquet')\n",
    "# cat_names = ['user_id','item_id','platform','city','device','current_filters'] + [i for i in test.columns if i.startswith('is_')]\n",
    "\n",
    "# for c in cat_names:\n",
    "#     print(c)\n",
    "#     encoder = MyLabelEncoder()\n",
    "#     train_encoded = encoder.fit_transform(train[c])\n",
    "#     try:\n",
    "#         test_encoded = encoder.transform(test[c])\n",
    "#     except:\n",
    "#         print(f'{c} failed')\n",
    "#         continue\n",
    "\n",
    "# del train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Data preprocessing by cudf</center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# data_pair = pd.read_pickle('cache/data_pair_all.pkl')\n",
    "\n",
    "# train = data_pair[data_pair.clickout_missing==0]\n",
    "# test = data_pair[data_pair.clickout_missing>0]\n",
    "\n",
    "# valid = train.loc[train['row_id'] % 5 == 1]\n",
    "# train = train.loc[train['row_id'] % 5 != 1]\n",
    "\n",
    "# train.reset_index(drop=True, inplace=True)\n",
    "# valid.reset_index(drop=True, inplace=True)\n",
    "# test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# train.to_parquet('train.parquet')\n",
    "# valid.to_parquet('valid.parquet')\n",
    "# test.to_parquet('test.parquet')\n",
    "\n",
    "# print(train.shape, valid.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/col_names.pkl', 'rb') as f: col_names = pickle.load(f)\n",
    "cat_names, cont_names = col_names['cat_names'], col_names['cont_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_name = [TRAIN, VALID, TEST]\n",
    "# data = {}\n",
    "# for name in ds_name:\n",
    "#     ds = cudf.read_parquet(f\"{name}.parquet\")\n",
    "#     for i, n in enumerate(ds.columns):\n",
    "#         df = ds[n].to_frame().to_pandas()\n",
    "#         if not os.path.exists(f\"cache/{name}\"):\n",
    "#             os.mkdir(f\"cache/{name}\")\n",
    "#         df.to_parquet(f\"cache/{name}/{n}.parquet\")\n",
    "#     del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Test process entire colum by column</h3> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train use 64.16728401184082 seconds\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PreprocessingColByCol' object has no attribute 'category_encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d76cc63c7605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreproc_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name} use {time()-start} seconds\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-d23797ddf96a>\u001b[0m in \u001b[0;36mpreproc_dataframe\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mcats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcont_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-d23797ddf96a>\u001b[0m in \u001b[0;36mcategorify\u001b[0;34m(self, col, col_name)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcategorify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_encoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PreprocessingColByCol' object has no attribute 'category_encoder'"
     ]
    }
   ],
   "source": [
    "random.shuffle(cat_names)\n",
    "random.shuffle(cont_names)\n",
    "proc = PreprocessingColByCol(path=\"cache\", cat_names=cat_names, cont_names=cont_names, label_name='target')\n",
    "ds_name = [TRAIN,VALID]\n",
    "data = {}\n",
    "for name in ds_name:\n",
    "    start = time()\n",
    "    x, y = proc.preproc_dataframe(mode=name)\n",
    "    print(f\"{name} use {time()-start} seconds\\n\")\n",
    "    data[name] = (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Test process entire df</h3> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "proc = PreprocessDF(cat_names=cat_names, cont_names=cont_names, label_name='target', to_cpu=True)\n",
    "ds_name = [TEST]\n",
    "data = {}\n",
    "for name in ds_name:\n",
    "    ds = cudf.read_parquet(f\"{name}.parquet\")\n",
    "    x, y = proc.preproc_dataframe(ds, mode=name)\n",
    "    data[name] = (x, y)\n",
    "    del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, ((cats, conts), y) in data.items():\n",
    "    print(name, cats.shape, conts.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Test fastai </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "procs = [FillMissing, Normalize, Categorify]\n",
    "train['is_va'] = train.row_id%5 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cat_names =[]\n",
    "test_list = TabularList.from_df(test, path='./', cat_names=cat_names, cont_names=cont_names)\n",
    "train_list = TabularList.from_df(train, path='./', cat_names=cat_names, cont_names=cont_names, procs=procs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_list = train_list.split_from_df('is_va')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_list_labeled = train_list.label_from_df(cols='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_list_labeled_test = train_list_labeled.add_test(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_tab = train_list_labeled_test.databunch(num_workers=10,bs=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_tab.valid_ds + data_tab.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
