{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import nvstrings\n",
    "import warnings\n",
    "import cudf as gd\n",
    "from numba import cuda\n",
    "from sklearn.metrics import roc_auc_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranknorm_in_group(df,col,ascending=True):\n",
    "    # df is a cudf dataframe with a column row_id, pair_row_id and col\n",
    "    df = df.sort_values(by=['row_id',col],ascending=ascending)\n",
    "    \n",
    "    def ranknorm_in_group(row_id,rank,rank_norm):\n",
    "        N = len(row_id)\n",
    "        for i in range(cuda.threadIdx.x, N, cuda.blockDim.x):\n",
    "            rank[i] = i\n",
    "            rank_norm[i] = i*1.0/N\n",
    "            \n",
    "    df = df.groupby('row_id',method=\"cudf\").apply_grouped(ranknorm_in_group,incols=['row_id'],\n",
    "                                  outcols={'rank': np.int32,\n",
    "                                          'rank_norm':np.float32},\n",
    "                                  tpb=32)\n",
    "    df = df.sort_values(by='all_row_id')\n",
    "    cols = []\n",
    "    for i in df.columns:\n",
    "        if i.startswith('rank'):\n",
    "            cols.append('%s_%s'%(col,i))\n",
    "        else:\n",
    "            cols.append(i)\n",
    "    df.columns = cols\n",
    "    return df        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data pair and other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 s, sys: 11.9 s, total: 26.4 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_pair = pd.read_pickle('cache/data_pair_clickout_only.pkl')\n",
    "data_pair['all_row_id'] = np.arange(data_pair.shape[0])\n",
    "global_count = pd.read_pickle('cache/global_count.pkl')\n",
    "data_last_view_gd = gd.read_csv('cache/more_last_viewed_item.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_count_item_user_id_session_id_null ratio 0.956702350392898\n",
      "is_count_item_user_id_null ratio 0.9483320293308733\n",
      "CPU times: user 556 ms, sys: 1.14 s, total: 1.7 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global_count_cols = ['count_item_user_id_session_id','count_item_user_id']\n",
    "for col in global_count_cols:\n",
    "    data_pair[col] = global_count[col].values # they have the same row order\n",
    "    data_pair[col+'_norm'] = global_count[col+'_norm'].values\n",
    "    data_pair['is_%s_null'%col] = data_pair[col]<0\n",
    "    data_pair['is_%s_null'%col] = data_pair['is_%s_null'%col].astype(int)\n",
    "    print('is_%s_null ratio'%col, data_pair['is_%s_null'%col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_pair_gd = gd.from_pandas(data_pair[['all_row_id','row_id']])\n",
    "data_last_view_gd.drop_column('reference')\n",
    "data_last_view_gd = data_pair_gd.merge(data_last_view_gd,on='row_id',how='left')\n",
    "data_last_view_gd = data_last_view_gd.sort_values('all_row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_last_view_gd.shape,data_pair.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cols = []\n",
    "for col in data_last_view_gd.columns:\n",
    "    if col not in ['row_id','all_row_id']:\n",
    "        data_pair[col] = data_last_view_gd[col].to_pandas().values\n",
    "        print(col,'done')\n",
    "        cols.append(col)\n",
    "del data_last_view_gd\n",
    "del data_pair_gd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add is_last and delta_last features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "last_item_cols = []\n",
    "delta_last_item_cols = []\n",
    "for i in cols:\n",
    "    if 'reference' in i:\n",
    "        col = 'is_%s'%i\n",
    "        data_pair[col] = data_pair['item_id'] == data_pair[i]\n",
    "        last_item_cols.append(col)\n",
    "        data_pair[col] = data_pair[col].astype(int)\n",
    "    else:\n",
    "        tag = i.split('_')[3]\n",
    "        col = 'delta_%s'%i\n",
    "        data_pair[col] = data_pair[tag] - data_pair[i]\n",
    "        delta_last_item_cols.append(col)\n",
    "        data_pair[col] = data_pair[col].astype(float)\n",
    "    data_pair.drop(i,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pair.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# smaller means more click\n",
    "ascending_cols = ['price']\n",
    "print(ascending_cols)\n",
    "# greater means more click\n",
    "descending_cols = ['item_count','count_item_user_id_session_id','count_item_user_id']\n",
    "print(descending_cols)\n",
    "\n",
    "to_rank_cols = ascending_cols + descending_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ascendings = [True if col in ascending_cols else False for col in to_rank_cols]\n",
    "\n",
    "for col,ascending in zip(to_rank_cols,ascendings):\n",
    "    df = gd.from_pandas(data_pair[['row_id','all_row_id',col]])\n",
    "    df = ranknorm_in_group(df,col,ascending=ascending) # lower price higher click\n",
    "    \n",
    "    data_pair['%s_rank'%col] = df['%s_rank'%col].to_pandas().values\n",
    "    data_pair['%s_rank_norm'%col] = df['%s_rank_norm'%col].to_pandas().values\n",
    "    print(col,'done','ascending' if ascending else 'desending')\n",
    "    del df # save gpu memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pair.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be aware there are sessions without positive items in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dg = data_pair[['row_id','target','clickout_missing']]\n",
    "dg = dg.groupby('row_id').agg({'target':'max'})\n",
    "dg.columns = ['max_target']\n",
    "dg = dg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_pair.loc[data_pair['clickout_missing']==0,'row_id'].unique().shape,(dg['max_target']>0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(data_pair.shape)\n",
    "mask = (data_pair['clickout_missing']==0)&(data_pair.row_id.isin(dg.loc[dg['max_target']>0,'row_id']))\n",
    "print(data_pair[mask].shape)\n",
    "print(data_pair.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_pair.drop(['all_row_id','action_type','is_test'],axis=1).to_pickle('cache/data_pair_all.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
