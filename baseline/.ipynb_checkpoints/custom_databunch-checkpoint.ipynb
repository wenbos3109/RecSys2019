{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Our inputs data are tensors resulting from cudf processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "GPU_id = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_pickle(\"/datasets/trivago/preproc/data_pair_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>candidate_order</th>\n",
       "      <th>item_id</th>\n",
       "      <th>price</th>\n",
       "      <th>row_id_count</th>\n",
       "      <th>item_count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>step</th>\n",
       "      <th>...</th>\n",
       "      <th>item_past_6</th>\n",
       "      <th>item_past_7</th>\n",
       "      <th>item_past_8</th>\n",
       "      <th>item_past_9</th>\n",
       "      <th>num_past_items</th>\n",
       "      <th>has_past</th>\n",
       "      <th>search_destination</th>\n",
       "      <th>search_poi</th>\n",
       "      <th>nb_shared_filters</th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147528</td>\n",
       "      <td>1.050011</td>\n",
       "      <td>193861</td>\n",
       "      <td>-0.441959</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.508469</td>\n",
       "      <td>B3QVP6A5RRMD</td>\n",
       "      <td>fd460d6f31ffe</td>\n",
       "      <td>1541392347</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Lima, Peru</td>\n",
       "      <td>Miraflores</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147528</td>\n",
       "      <td>-0.767499</td>\n",
       "      <td>1276522</td>\n",
       "      <td>-0.522123</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.537149</td>\n",
       "      <td>B3QVP6A5RRMD</td>\n",
       "      <td>fd460d6f31ffe</td>\n",
       "      <td>1541392347</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Lima, Peru</td>\n",
       "      <td>Miraflores</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147528</td>\n",
       "      <td>0.910203</td>\n",
       "      <td>6007390</td>\n",
       "      <td>-0.436233</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.298804</td>\n",
       "      <td>B3QVP6A5RRMD</td>\n",
       "      <td>fd460d6f31ffe</td>\n",
       "      <td>1541392347</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Lima, Peru</td>\n",
       "      <td>Miraflores</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  candidate_order  item_id     price  row_id_count  item_count  \\\n",
       "0  147528         1.050011   193861 -0.441959            25   -0.508469   \n",
       "1  147528        -0.767499  1276522 -0.522123            25   -0.537149   \n",
       "2  147528         0.910203  6007390 -0.436233            25   -0.298804   \n",
       "\n",
       "        user_id     session_id   timestamp  step    ...      item_past_6  \\\n",
       "0  B3QVP6A5RRMD  fd460d6f31ffe  1541392347     2    ...                0   \n",
       "1  B3QVP6A5RRMD  fd460d6f31ffe  1541392347     2    ...                0   \n",
       "2  B3QVP6A5RRMD  fd460d6f31ffe  1541392347     2    ...                0   \n",
       "\n",
       "  item_past_7 item_past_8 item_past_9 num_past_items  has_past  \\\n",
       "0           0           0           0              0     False   \n",
       "1           0           0           0              0     False   \n",
       "2           0           0           0              0     False   \n",
       "\n",
       "   search_destination  search_poi  nb_shared_filters compliance  \n",
       "0          Lima, Peru  Miraflores                0.0        0.0  \n",
       "1          Lima, Peru  Miraflores                0.0        0.0  \n",
       "2          Lima, Peru  Miraflores                0.0        0.0  \n",
       "\n",
       "[3 rows x 257 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42739624, 257) (5760337, 257)\n",
      "CPU times: user 41 s, sys: 34.1 s, total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = data[data.clickout_missing==0]\n",
    "test = data[data.clickout_missing>0]\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got cols\n",
      "got valids\n",
      "got tests\n",
      "CPU times: user 2.86 s, sys: 4.08 s, total: 6.94 s\n",
      "Wall time: 8.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from fastai.basic_data import *\n",
    "from fastai.tabular import *\n",
    "cat_names = ['user_id','item_id','platform','city','device','current_filters'] + [i for i in train.columns if i.startswith('is_')] \n",
    "cont_names = ['price','candidate_order','item_count'] + [i for i in train.columns if i.startswith('count') or 'rank' in i or i.startswith('delta_')]\n",
    "\n",
    "print('got cols')\n",
    "\n",
    "procs = [FillMissing, Categorify]\n",
    "train['is_va'] = train.row_id%5 == 0\n",
    "\n",
    "print('got valids')\n",
    "\n",
    "test_list = TabularList.from_df(test, path='./', cat_names=cat_names, cont_names=cont_names)\n",
    "print('got tests')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got data\n",
      "CPU times: user 7min 55s, sys: 7min 7s, total: 15min 2s\n",
      "Wall time: 15min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = (TabularList.from_df(train, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
    "                           .split_from_df('is_va')\n",
    "                           .label_from_df(cols='target')\n",
    "                           .add_test(test_list))\n",
    "print('got data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Get the size of vocab of each categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train.y[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key user_id : 715920\n",
      "key item_id : 850794\n",
      "key platform : 56\n",
      "key city : 32763\n",
      "key device : 4\n",
      "key current_filters : 27842\n",
      "key is_count_item_user_id_session_id_null : 3\n",
      "key is_count_item_user_id_null : 3\n",
      "key is_last_viewed_item_reference_any : 3\n",
      "key is_last_viewed_item_reference_interaction item rating : 3\n",
      "key is_last_viewed_item_reference_interaction item image : 3\n",
      "key is_last_viewed_item_reference_interaction item info : 3\n",
      "key is_last_viewed_item_reference_interaction item deals : 3\n",
      "key is_1 Star : 3\n",
      "key is_2 Star : 3\n",
      "key is_3 Star : 3\n",
      "key is_4 Star : 3\n",
      "key is_5 Star : 3\n",
      "key is_Accessible Hotel : 3\n",
      "key is_Accessible Parking : 3\n",
      "key is_Adults Only : 3\n",
      "key is_Air Conditioning : 3\n",
      "key is_Airport Hotel : 3\n",
      "key is_Airport Shuttle : 3\n",
      "key is_All Inclusive (Upon Inquiry) : 3\n",
      "key is_Balcony : 3\n",
      "key is_Bathtub : 3\n",
      "key is_Beach : 3\n",
      "key is_Beach Bar : 3\n",
      "key is_Beauty Salon : 3\n",
      "key is_Bed & Breakfast : 3\n",
      "key is_Bike Rental : 3\n",
      "key is_Boat Rental : 3\n",
      "key is_Body Treatments : 3\n",
      "key is_Boutique Hotel : 3\n",
      "key is_Bowling : 3\n",
      "key is_Bungalows : 3\n",
      "key is_Business Centre : 3\n",
      "key is_Business Hotel : 3\n",
      "key is_Cable TV : 3\n",
      "key is_Camping Site : 3\n",
      "key is_Car Park : 3\n",
      "key is_Casa Rural (ES) : 3\n",
      "key is_Casino (Hotel) : 3\n",
      "key is_Central Heating : 3\n",
      "key is_Childcare : 3\n",
      "key is_Club Hotel : 3\n",
      "key is_Computer with Internet : 3\n",
      "key is_Concierge : 3\n",
      "key is_Conference Rooms : 3\n",
      "key is_Convenience Store : 3\n",
      "key is_Convention Hotel : 3\n",
      "key is_Cosmetic Mirror : 3\n",
      "key is_Cot : 3\n",
      "key is_Country Hotel : 3\n",
      "key is_Deck Chairs : 3\n",
      "key is_Design Hotel : 3\n",
      "key is_Desk : 3\n",
      "key is_Direct beach access : 3\n",
      "key is_Diving : 3\n",
      "key is_Doctor On-Site : 3\n",
      "key is_Eco-Friendly hotel : 3\n",
      "key is_Electric Kettle : 3\n",
      "key is_Excellent Rating : 3\n",
      "key is_Express Check-In / Check-Out : 3\n",
      "key is_Family Friendly : 3\n",
      "key is_Fan : 3\n",
      "key is_Farmstay : 3\n",
      "key is_Fitness : 3\n",
      "key is_Flatscreen TV : 3\n",
      "key is_Free WiFi (Combined) : 3\n",
      "key is_Free WiFi (Public Areas) : 3\n",
      "key is_Free WiFi (Rooms) : 3\n",
      "key is_Fridge : 3\n",
      "key is_From 2 Stars : 3\n",
      "key is_From 3 Stars : 3\n",
      "key is_From 4 Stars : 3\n",
      "key is_Gay-friendly : 3\n",
      "key is_Golf Course : 3\n",
      "key is_Good Rating : 3\n",
      "key is_Guest House : 3\n",
      "key is_Gym : 3\n",
      "key is_Hairdresser : 3\n",
      "key is_Hairdryer : 3\n",
      "key is_Halal Food : 3\n",
      "key is_Hammam : 3\n",
      "key is_Health Retreat : 3\n",
      "key is_Hiking Trail : 3\n",
      "key is_Honeymoon : 3\n",
      "key is_Horse Riding : 3\n",
      "key is_Hostal (ES) : 3\n",
      "key is_Hostel : 3\n",
      "key is_Hot Stone Massage : 3\n",
      "key is_Hotel : 3\n",
      "key is_Hotel Bar : 3\n",
      "key is_House / Apartment : 3\n",
      "key is_Hydrotherapy : 3\n",
      "key is_Hypoallergenic Bedding : 3\n",
      "key is_Hypoallergenic Rooms : 3\n",
      "key is_Ironing Board : 3\n",
      "key is_Jacuzzi (Hotel) : 3\n",
      "key is_Kids Club : 2\n",
      "key is_Kosher Food : 3\n",
      "key is_Large Groups : 3\n",
      "key is_Laundry Service : 3\n",
      "key is_Lift : 3\n",
      "key is_Luxury Hotel : 3\n",
      "key is_Massage : 3\n",
      "key is_Microwave : 3\n",
      "key is_Minigolf : 3\n",
      "key is_Motel : 3\n",
      "key is_Nightclub : 3\n",
      "key is_Non-Smoking Rooms : 3\n",
      "key is_On-Site Boutique Shopping : 3\n",
      "key is_Openable Windows : 3\n",
      "key is_Organised Activities : 3\n",
      "key is_Pet Friendly : 3\n",
      "key is_Playground : 3\n",
      "key is_Pool Table : 3\n",
      "key is_Porter : 3\n",
      "key is_Pousada (BR) : 3\n",
      "key is_Radio : 3\n",
      "key is_Reception (24/7) : 3\n",
      "key is_Resort : 3\n",
      "key is_Restaurant : 3\n",
      "key is_Romantic : 3\n",
      "key is_Room Service : 3\n",
      "key is_Room Service (24/7) : 3\n",
      "key is_Safe (Hotel) : 3\n",
      "key is_Safe (Rooms) : 3\n",
      "key is_Sailing : 3\n",
      "key is_Satellite TV : 3\n",
      "key is_Satisfactory Rating : 3\n",
      "key is_Sauna : 3\n",
      "key is_Self Catering : 3\n",
      "key is_Senior Travellers : 3\n",
      "key is_Serviced Apartment : 3\n",
      "key is_Shooting Sports : 3\n",
      "key is_Shower : 3\n",
      "key is_Singles : 3\n",
      "key is_Sitting Area (Rooms) : 3\n",
      "key is_Ski Resort : 3\n",
      "key is_Skiing : 3\n",
      "key is_Solarium : 3\n",
      "key is_Spa (Wellness Facility) : 3\n",
      "key is_Spa Hotel : 3\n",
      "key is_Steam Room : 3\n",
      "key is_Sun Umbrellas : 3\n",
      "key is_Surfing : 3\n",
      "key is_Swimming Pool (Bar) : 3\n",
      "key is_Swimming Pool (Combined Filter) : 3\n",
      "key is_Swimming Pool (Indoor) : 3\n",
      "key is_Swimming Pool (Outdoor) : 3\n",
      "key is_Szep Kartya : 3\n",
      "key is_Table Tennis : 3\n",
      "key is_Telephone : 3\n",
      "key is_Teleprinter : 3\n",
      "key is_Television : 3\n",
      "key is_Tennis Court : 3\n",
      "key is_Tennis Court (Indoor) : 3\n",
      "key is_Terrace (Hotel) : 3\n",
      "key is_Theme Hotel : 3\n",
      "key is_Towels : 3\n",
      "key is_Very Good Rating : 3\n",
      "key is_Volleyball : 3\n",
      "key is_Washing Machine : 3\n",
      "key is_Water Slide : 3\n",
      "key is_Wheelchair Accessible : 3\n",
      "key is_WiFi (Public Areas) : 3\n",
      "key is_WiFi (Rooms) : 3\n",
      "key is_va : 2\n"
     ]
    }
   ],
   "source": [
    "for key, v in data.train.x.classes.items(): \n",
    "    print(\"key %s : %s\" %(key, len(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> New Data Bunch </center> </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the rest of the notebook, we'll assume we have built the following processed tensors ( using cudf)  : \n",
    "    - train : cat_tensor, cont_tensor, label_tensor \n",
    "    \n",
    "    - valid : cat_tensor, cont_tensor, label_tensor \n",
    "    \n",
    "    - test : cat_tensor, cont_tensor, label_tensor \n",
    "    \n",
    "- The size of vocaublary of each categorical variable is also known "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_tensors = torch.cat([data.train.x[i].data[0] for i in range(10000)], dim=0).reshape(10000,171)\n",
    "cont_tensors = torch.cat([data.train.x[i].data[1] for i in range(10000)], dim=0).reshape(10000,37)\n",
    "labels = tensor([data.train.y[i].data for i in range(10000)]).reshape(10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tensor batch loader  : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchDataset(object):\n",
    "    \"\"\"An abstract class representing a Batch Dataset.\n",
    "    All other datasets should subclass this. All subclasses should override\n",
    "    ``__len__``, which provides the size of the dataset, ``__getitem__``,\n",
    "    supporting integer indexing of batches in range from 0 to len(self)//batchsize exclusive,\n",
    "    and ``shuffle`` which randomly shuffles the data, generally called per epoch.\n",
    "    Batch datasets are meant to be iterated over in order rather than randomly accessed\n",
    "    so the randomization has to happen first.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def shuffle(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class TensorBatchDataset(BatchDataset):\n",
    "    \"\"\"Batch Dataset wrapping Tensors.\n",
    "    Arguments:\n",
    "        *tensors (Tensor): tensors that have the same size of the first dimension.\n",
    "        batch_size: The size of the batch to return\n",
    "        pin_memory (bool, optional): If ``True``, the dataset will be pinned memory for faster copy to GPU.\n",
    "        I saw no performance improvement to doing so but results may vary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tensors, batch_size=1, pin_memory=False):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        \n",
    "        \n",
    "        self.tensors = tensors\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.num_samples = tensors[0].size(0)\n",
    "\n",
    "        if pin_memory:\n",
    "            for tensor in self.tensors:\n",
    "                tensor.pin_memory()\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.num_samples % self.batch_size == 0:\n",
    "            return self.num_samples // self.batch_size\n",
    "        else:\n",
    "            return self.num_samples // self.batch_size + 1\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        idx = item * self.batch_size\n",
    "        # Need to handle odd sized batches if data isn't divisible by batchsize\n",
    "        if idx < self.num_samples and (\n",
    "                idx + self.batch_size < self.num_samples or self.num_samples % self.batch_size == 0):\n",
    "            return [tensor[idx:idx + self.batch_size] for tensor in self.tensors]\n",
    "\n",
    "        elif idx < self.num_samples and idx + self.batch_size > self.num_samples:\n",
    "            return [tensor[idx:] for tensor in self.tensors]\n",
    "        else:\n",
    "            raise IndexError\n",
    "\n",
    "    def __add__(self, tensors):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        assert len(self.tensors) == len(tensors)\n",
    "        assert all(self_tensor[0].shape == tensor[0].shape for self_tensor, tensor in zip(self.tensors, tensors))\n",
    "\n",
    "        num_add_samples = tensors[0].size(0)\n",
    "        self.num_samples = self.num_samples + num_add_samples\n",
    "        self.tensors = [torch.cat((self_tensor, tensor)) for self_tensor, tensor in zip(self.tensors, tensors)]\n",
    "\n",
    "    def shuffle(self):\n",
    "        idx = torch.randperm(self.num_samples, dtype=torch.int64)\n",
    "        self.tensors = [tensor[idx] for tensor in self.tensors]\n",
    "        \n",
    "        \n",
    "import torch\n",
    "from torch import _utils\n",
    "\n",
    "class BatchDataLoader(object):\n",
    "    \"\"\"Batch Data loader. Takes in a batch dataset and returns iterators that return whole batches of data.\n",
    "    Arguments:\n",
    "        dataset (BatchDataset): dataset from which to load the data.\n",
    "        shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
    "            at every epoch (default: ``False``).\n",
    "        pin_memory (bool, optional): If ``True``, the data loader will copy tensors\n",
    "            into CUDA pinned memory before returning them.\n",
    "        drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
    "            if the dataset size is not divisible by the batch size. If ``False`` and\n",
    "            the size of dataset is not divisible by the batch size, then the last batch\n",
    "            will be smaller. (default: ``False``)\n",
    "        device: str,  return batch data in the related device  (default: )\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batchdataset, shuffle=False,\n",
    "                 pin_memory=False, drop_last=False, device='cuda'):\n",
    "\n",
    "        self.batch_size = batchdataset.batch_size\n",
    "        self.dataset = batchdataset\n",
    "        self.shuffle = shuffle\n",
    "        self.pin_memory = pin_memory\n",
    "        self.drop_last = drop_last\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        return _BatchDataLoaderIter(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last and self.dataset.num_samples%self.batch_size != 0:\n",
    "            return len(self.dataset)-1\n",
    "        else:\n",
    "            return len(self.dataset)\n",
    "\n",
    "    \n",
    "class _BatchDataLoaderIter(object):\n",
    "    \"\"\"Iterates once over the BatchDataLoader's batchdataset, shuffling if requested\"\"\"\n",
    "    def __init__(self, loader):\n",
    "        self.batchdataset = loader.dataset\n",
    "        self.batch_size = loader.batch_size\n",
    "        self.pin_memory = loader.pin_memory and torch.cuda.is_available()\n",
    "        self.drop_last = loader.drop_last\n",
    "        self.device = loader.device\n",
    "\n",
    "        if loader.shuffle:\n",
    "            self.batchdataset.shuffle()\n",
    "\n",
    "        self.idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last and self.batchdataset.num_samples%self.batch_size != 0:\n",
    "            return len(self.batchdataset)-1\n",
    "        else:\n",
    "            return len(self.batchdataset)\n",
    "         \n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.idx >= len(self):\n",
    "            raise StopIteration\n",
    "        batch = self.batchdataset[self.idx]\n",
    "        # Note Pinning memory was ~10% _slower_ for the test examples I explored\n",
    "        if self.pin_memory:\n",
    "            batch = _utils.pin_memory.pin_memory_batch(batch)\n",
    "        self.idx = self.idx+1\n",
    "        # move the batch data to device \n",
    "        batch = to_device(batch, self.device)\n",
    "        # return in the form of : xb,yb = (x_cat, x_cont), y\n",
    "        return (batch[0],batch[1]), batch[2]\n",
    "\n",
    "    next = __next__  # Python 2 compatibility\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchdataset = TensorBatchDataset([cat_tensors, cont_tensors, labels], batch_size=10)\n",
    "dataloader = BatchDataLoader(batchdataset, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataloader.__iter__().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 171]), torch.Size([10, 37]), torch.Size([10]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0][0].shape, t[0][1].shape, t[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[259235,  74035,      3,  ...,      1,      2,      1],\n",
       "        [259235, 153471,      3,  ...,      2,      2,      1],\n",
       "        [259235, 479807,      3,  ...,      2,      2,      1],\n",
       "        ...,\n",
       "        [259235, 105181,      3,  ...,      2,      2,      1],\n",
       "        [259235,  53309,      3,  ...,      2,      2,      1],\n",
       "        [259235, 146892,      3,  ...,      2,      2,      1]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a custom databunch fastai that takes a TensorBatchDataLoader instead of the DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basic_data import DataBunch\n",
    "class BatchDataBunch(DataBunch):\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs=None, \n",
    "                      num_workers:int=defaults.cpus, device:torch.device=None,\n",
    "                      collate_fn:Callable=data_collate, size:int=None, **kwargs)->'BatchDataBunch':\n",
    "        \n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        \n",
    "        datasets = [TensorBatchDataset(train_ds, batch_size=bs), \n",
    "                    TensorBatchDataset(valid_ds, batch_size=val_bs)]\n",
    "        \n",
    "        if test_ds is not None:\n",
    "            datasets.append(TensorBatchDataset(test_ds, batch_size=val_bs))\n",
    "        else: \n",
    "            datasets.append(test_ds)\n",
    "        \n",
    "        cls.device = defaults.device if device is None else device\n",
    "        \n",
    "        dls = [BatchDataLoader(d, shuffle=s, pin_memory=False, drop_last=s, device=cls.device) for d,s in\n",
    "               zip(datasets,(True,False,False)) if d is not None]\n",
    "\n",
    "        cls.path = path \n",
    "        \n",
    "        cls.dls = dls\n",
    "    \n",
    "        \n",
    "        \n",
    "        assert not isinstance(dls[0],DeviceDataLoader)\n",
    "        \n",
    "        \n",
    "        # load batch in device \n",
    "        \n",
    "        if test_ds is not None:\n",
    "            cls.train_dl, cls.valid_dl, cls.test_dl = dls\n",
    "        else: \n",
    "            cls.train_dl, cls.valid_dl = dls\n",
    "            \n",
    "            \n",
    "        cls.path = Path(path)\n",
    "        return cls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [cat_tensors, cont_tensors, labels]\n",
    "validation = [cat_tensors, cont_tensors, labels]\n",
    "test = [cat_tensors, cont_tensors, labels]\n",
    "databunch = BatchDataBunch.create(train, validation, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import TabularModel\n",
    "\n",
    "model = TabularModel(emb_szs = [(715920,16), (850794,16), (56,4), (32763,8), (4,1), (27842,8)], n_cont=37, \n",
    "                     out_sz=2, layers=[128,64], ps=0.1, emb_drop=0.2,  y_range=[0,1])\n",
    "\n",
    "learn =  Learner(databunch, model,metrics=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(715920, 16)\n",
       "    (1): Embedding(850794, 16)\n",
       "    (2): Embedding(56, 4)\n",
       "    (3): Embedding(32763, 8)\n",
       "    (4): Embedding(4, 1)\n",
       "    (5): Embedding(27842, 8)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.2)\n",
       "  (bn_cont): BatchNorm1d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=90, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.1)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.1)\n",
       "    (8): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.542712</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
