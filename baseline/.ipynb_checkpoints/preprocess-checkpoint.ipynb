{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_id = 5\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nvstrings, nvcategory\n",
    "import warnings\n",
    "import cudf\n",
    "import torch\n",
    "\n",
    "from fastai import *\n",
    "from fastai.basic_data import *\n",
    "from librmm_cffi import librmm\n",
    "from fastai_modified.core_cudf import *\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "from cuml.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "%reload_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _enforce_str(y: cudf.Series) -> cudf.Series:\n",
    "    \"\"\"\n",
    "    Ensure that nvcategory is being given strings\n",
    "    \"\"\"\n",
    "    if y.dtype != \"object\":\n",
    "        return y.astype(\"str\")\n",
    "    return y\n",
    "\n",
    "class LabelEncoder(object):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self._cats: nvcategory.nvcategory = None\n",
    "        self._dtype = None\n",
    "        self._fitted: bool = False\n",
    "\n",
    "    def _check_is_fitted(self):\n",
    "        if not self._fitted:\n",
    "            raise TypeError(\"Model must first be .fit()\")\n",
    "\n",
    "    def fit(self, y: cudf.Series) -> \"LabelEncoder\":\n",
    "        self._dtype = y.dtype\n",
    "\n",
    "        y = _enforce_str(y)\n",
    "\n",
    "        self._cats = nvcategory.from_strings(y.data)\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, y: cudf.Series) -> cudf.Series:\n",
    "        self._check_is_fitted()\n",
    "        y = _enforce_str(y)\n",
    "        encoded = cudf.Series(\n",
    "            nvcategory.from_strings(y.data)\n",
    "                .set_keys(self._cats.keys())\n",
    "                .values()\n",
    "        )\n",
    "        return encoded.replace(-1, 0)\n",
    "\n",
    "    def fit_transform(self, y: cudf.Series) -> cudf.Series:\n",
    "        self._dtype = y.dtype\n",
    "\n",
    "        # Convert y to nvstrings series, if it isn't one\n",
    "        y = _enforce_str(y)\n",
    "\n",
    "        # Bottleneck is here, despite everything being done on the device\n",
    "        self._cats = nvcategory.from_strings(y.data)\n",
    "\n",
    "        self._fitted = True\n",
    "        arr: librmm.device_array = librmm.device_array(\n",
    "            y.data.size(), dtype=np.int32\n",
    "        )\n",
    "        self._cats.values(devptr=arr.device_ctypes_pointer.value)\n",
    "        return cudf.Series(arr)\n",
    "\n",
    "    def inverse_transform(self, y: cudf.Series) -> cudf.Series:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularProc():\n",
    "    def process_df(self, gdf: cudf.DataFrame, train: bool, cat_names: list, cont_names: list):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Normalize(TabularProc):\n",
    "    \"Normalize the continuous variables.\"\n",
    "    means, stds = {}, {}\n",
    "    def process_df(self, gdf: cudf.DataFrame, train: bool, cat_names: list, cont_names: list):\n",
    "        if train:\n",
    "            self.means.update({name: mean for name, mean in zip(cont_names, gdf[cont_names].mean())})\n",
    "            self.stds.update({name: mean for name, mean in zip(cont_names, gdf[cont_names].std())})\n",
    "        for name in cont_names:\n",
    "            gdf[name] = (gdf[name] - self.means[name]) / (1e-7 + self.stds[name])\n",
    "            gdf[name] = gdf[name].astype('float32')\n",
    "\n",
    "class FillMissing(TabularProc):\n",
    "    MEDIAN = \"median\"\n",
    "    CONSTANT = \"constant\"\n",
    "    def __init__(self, fill_strategy=MEDIAN, fill_val=0, add_col=True):\n",
    "        self.fill_strategy = fill_strategy\n",
    "        self.fill_val = fill_val\n",
    "        self.add_col = add_col\n",
    "        self.train_cont_names_na = []\n",
    "        self.filler = {}\n",
    "\n",
    "    def process_df(self, gdf: cudf.DataFrame, train: bool, cat_names: list, cont_names: list):\n",
    "        na_names = [name for name in cont_names if gdf[name].isna().sum()]\n",
    "        if len(na_names) == 0: return\n",
    "        cur_filler = {}\n",
    "        if train:\n",
    "            self.train_cont_names_na.extend(na_names)\n",
    "            if self.fill_strategy == self.MEDIAN:\n",
    "                cur_filler = {name: self.get_median(gdf[name]) for name in na_names}\n",
    "            elif self.fill_strategy == self.CONSTANT:\n",
    "                cur_filler = {name: self.fill_val for name in na_names}\n",
    "            else:\n",
    "                cur_filler = {name: gdf[name].value_counts().index[0] for name in na_names}\n",
    "            self.filler.update(cur_filler)\n",
    "        elif not set(na_names).issubset(set(self.train_cont_names_na)):\n",
    "            raise Exception(f\"\"\"There are nan values in field {na_names} but there were none \n",
    "            in the training set. Please fix those manually.\"\"\")\n",
    "        if self.add_col: self.add_na_indicators(gdf, na_names, cat_names)\n",
    "        gdf[na_names].fillna(cur_filler, inplace=True)\n",
    "\n",
    "    def add_na_indicators(self, gdf: cudf.DataFrame, na_names, cat_names):\n",
    "        for name in na_names:\n",
    "            name_na = name + \"_na\"\n",
    "            gdf[name_na] = gdf[name].isna()\n",
    "            if name_na not in cat_names: cat_names.append(name_na)\n",
    "\n",
    "    def get_median(self, col: cudf.Series):\n",
    "        col = col.dropna().reset_index(drop=True).sort_values()\n",
    "        return col[len(col)//2]\n",
    "\n",
    "class Categorify(TabularProc):\n",
    "    \"Transform the categorical variables to that type.\"\n",
    "    category_encoders = {}\n",
    "    embed_sz = {}\n",
    "    cat_names = []\n",
    "    def process_df(self, gdf: cudf.DataFrame, train: bool, cat_names: list, cont_names: list):\n",
    "        self.cat_names.extend(cat_names)\n",
    "        for name in cat_names:\n",
    "            if train:\n",
    "                le = LabelEncoder()\n",
    "                self.category_encoders[name] = le\n",
    "                gdf[name] = le.fit_transform(gdf[name].append([None]))[:-1]\n",
    "            else:\n",
    "                gdf[name] = self.category_encoders[name].transform(gdf[name].append([None]))[:-1]\n",
    "            gdf[name] = gdf[name].astype('int64')\n",
    "\n",
    "    def get_emb_sz(self):\n",
    "        work_in = {}\n",
    "        for key, val in self.category_encoders.items():\n",
    "            work_in[key] = len(val._cats.keys()) + 1\n",
    "        ret_list = [self.def_emb_sz(work_in, n) for n in self.cat_names]\n",
    "        return ret_list\n",
    "\n",
    "    def emb_sz_rule(self, n_cat: int) -> int:\n",
    "        return min(600, round(1.6 * n_cat ** 0.56))\n",
    "\n",
    "    def def_emb_sz(self, classes, n, sz_dict=None):\n",
    "        \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n",
    "        sz_dict = ifnone(sz_dict, {})\n",
    "        n_cat = classes[n]\n",
    "        sz = sz_dict.get(n, int(self.emb_sz_rule(n_cat)))  # rule of thumb\n",
    "        self.embed_sz[n] = sz\n",
    "        return n_cat, sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "    def __init__(self, cat_names, cont_names, label_name, preprocessors: list, to_cpu=True):\n",
    "        self.cat_names, self.cont_names, self.label_name = cat_names, cont_names, label_name\n",
    "        self.to_cpu = to_cpu\n",
    "        self.preprocessors = preprocessors\n",
    "        self.cpu = torch.device(\"cpu\")\n",
    "        self.cats, self.conts, self.label = [], [], []\n",
    "\n",
    "    def preproc_files(self, files, train=True):\n",
    "        for file in files:\n",
    "            gdf = cudf.read_parquet(file)\n",
    "            gdf_cat_names = [n for n in gdf.columns if n in self.cat_names]\n",
    "            gdf_cont_names = [n for n in gdf.columns if n in self.cont_names]\n",
    "            if is_listy(self.label_name):\n",
    "                gdf_label_names = [n for n in gdf.columns if n in self.label_name] \n",
    "            elif self.label_name in gdf.columns:\n",
    "                gdf_label_names = [self.label_name]\n",
    "            else:\n",
    "                gdf_label_names = []\n",
    "            for proc in self.preprocessors:\n",
    "                if not isinstance(proc, TabularProc):\n",
    "                    raise Exception(f\"{proc} is not a valid tabular processor\")\n",
    "                proc.process_df(gdf, train, gdf_cat_names, gdf_cont_names)\n",
    "            for n in gdf_label_names: \n",
    "                gdf[n] = gdf[n].astype('float32')\n",
    "            gdf_cats, gdf_conts, gdf_label = gdf[gdf_cat_names], gdf[gdf_cont_names], gdf[gdf_label_names]\n",
    "            del gdf\n",
    "            self.to_tensor(gdf_cats, torch.long, self.cats)\n",
    "            self.to_tensor(gdf_conts, torch.float32, self.conts)\n",
    "            self.to_tensor(gdf_label, torch.float32, self.label)\n",
    "            del gdf_cats, gdf_conts, gdf_label\n",
    "        cats = torch.cat(self.cats, dim=1) if self.cats\n",
    "        conts = torch.cat(self.conts, dim=1) if self.conts\n",
    "        label = torch.cat(self.label, dim=1) if self.label\n",
    "        return (cats, conts), label\n",
    "\n",
    "    def to_tensor(self, gdf: cudf.DataFrame, dtype, tensor_list):\n",
    "        if gdf.shape[0] == 0: return\n",
    "        t = from_dlpack(gdf.to_dlpack()).type(dtype)\n",
    "        t = t.unsqueeze(1) if gdf.shape[1] == 1 else t\n",
    "        t = t.to(self.cpu) if self.to_cpu else t\n",
    "        tensor_list.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <center> Pre processing </center> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = cudf.read_parquet('test.parquet')\n",
    "# idxs = torch.randperm(len(test.columns))\n",
    "# j = 0\n",
    "# files = []\n",
    "# strid = 20\n",
    "# for i in range(0, test.shape[1], strid):\n",
    "#     sub_columns = test.columns[idxs[i:i+stride]]\n",
    "#     file = f'cache/train_sub_{j}.parquet'\n",
    "#     test[sub_columns].to_pandas().to_parquet(file)\n",
    "#     files.append(file)\n",
    "#     j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/col_names.pkl', 'rb') as f: col_names = pickle.load(f)\n",
    "cat_names, cont_names = col_names['cat_names'], col_names['cont_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_list = [FillMissing(), Normalize(), Categorify()]\n",
    "preprocessor = Preprocess(cat_names=cat_names, cont_names=cont_names, label_name='target', preprocessors=proc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "files = ['train.parquet']\n",
    "(cats, conts), label = preprocessor.preproc_files(files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
