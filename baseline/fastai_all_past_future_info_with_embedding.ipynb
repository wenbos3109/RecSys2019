{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "import nvstrings\n",
    "import warnings\n",
    "import cudf as gd\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from datetime import date\n",
    "from fastai.callbacks import *\n",
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "from fastai.text import *\n",
    "from fastai.metrics import accuracy\n",
    "from multiprocessing import Process\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_id = 3\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2> Functions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#                       #\n",
    "# Metrics and callbacks #\n",
    "#                       #\n",
    "#########################\n",
    "\n",
    "def write_pkl(obj, file_path=None):\n",
    "    if not file_path:\n",
    "        date_time = date.fromtimestamp(time.time()).strftime(\"%m_%d_%Y_%H-%M-%S\")\n",
    "        file_path=f'{date_time}.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_out = pickle.dumps(obj, protocol=4)\n",
    "    with open(file_path, 'wb') as f_out:\n",
    "        for idx in range(0, len(bytes_out), max_bytes):\n",
    "            f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "\n",
    "\n",
    "def get_mean_reciprocal_rank(sub):\n",
    "    # sub is a pandas dataframe\n",
    "    # sub should have the following columns:\n",
    "    # 'row_id', 'prob', 'reference', 'item_id'\n",
    "    # sorted by prob in descending order for each group\n",
    "    sub = gd.from_pandas(sub)\n",
    "    \n",
    "    def get_order_in_group(prob,row_id,order):\n",
    "        for i in range(cuda.threadIdx.x, len(prob), cuda.blockDim.x):\n",
    "            order[i] = i\n",
    "\n",
    "    dg = sub.groupby('row_id',method=\"cudf\").apply_grouped(get_order_in_group,incols=['prob','row_id'],\n",
    "                                  outcols={'order': np.int32},\n",
    "                                  tpb=32)\n",
    "\n",
    "    dg = dg.to_pandas()\n",
    "    dg['order'] = 1.0/(1+dg['order'])\n",
    "    dg = dg[dg['reference']==dg['item_id']]\n",
    "    print(dg.isnull().values.any())\n",
    "    return dg['order'].mean()\n",
    "\n",
    "def auroc_score(input, target):\n",
    "    input, target = input.cpu().numpy()[:,1], target.cpu().numpy()\n",
    "    return roc_auc_score(target, input)\n",
    "\n",
    "# Callback to calculate AUC at the end of each epoch\n",
    "class AUROC(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['AUROC'])\n",
    "    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []\n",
    "\n",
    "    def on_batch_end(self, last_target, last_output, train, **kwargs):\n",
    "        if not train:\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if len(self.output) > 0:\n",
    "            output = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            preds = F.softmax(output, dim=1)\n",
    "            metric = auroc_score(preds, target)\n",
    "            return add_metrics(last_metrics, [metric])\n",
    "\n",
    "        \n",
    "def get_idx(x): \n",
    "    return 0 if pd.isnull(x) else id_to_index.get(str(x), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Data Processing </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/id_to_index.pkl', 'rb') as handle:\n",
    "    id_to_index = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#load tabular data \n",
    "data_pair = pd.read_pickle('cache/data_pair_all.pkl')\n",
    "data_pair = data_pair.drop(columns = [c for c in data_pair.columns if c.startswith('delta') or c.startswith('is')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_context = pd.read_csv('cache/context_info.csv')\n",
    "data_context['past_clickout_item'] = data_context['past_clickout_item'].apply(get_idx)\n",
    "data_context['future_clickout_item'] = data_context['future_clickout_item'].apply(get_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_pair = data_pair.merge(data_context, on='row_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pair['past_clickout_price_diff'] = data_pair['price'] - data_pair['past_clickout_price']\n",
    "data_pair['future_clickout_price_diff'] = data_pair['price'] - data_pair['future_clickout_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the train and test dataset \n",
    "train = data_pair[data_pair.clickout_missing==0]\n",
    "test = data_pair[data_pair.clickout_missing>0]\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Tabular model </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Input Data </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "cat_names = ['user_id','item_id','platform','city','device','current_filters']\n",
    "cat_names +=['past_clickout_available', \n",
    "             'past_clickout_is_same', \n",
    "             'past_clickout_impression_valid', \n",
    "             'future_clickout_available',\n",
    "             'future_clickout_is_same', \n",
    "             'future_clickout_impression_valid']\n",
    "\n",
    "cont_names = ['price','candidate_order','item_count'] + [i for i in train.columns if i.startswith('count') or 'rank' in i or i.startswith('delta_')]\n",
    "cont_names += [ 'past_clickout_step_diff', \n",
    "                'past_clickout_timestamp_diff',\n",
    "                'past_clickout_price', \n",
    "                'past_clickout_price_mean',  \n",
    "                'past_clickout_price_std',\n",
    "                'past_clickout_price_diff',\n",
    "                'cur_item_count_past',\n",
    "                'future_clickout_step_diff', \n",
    "                'future_clickout_timestamp_diff',\n",
    "                'future_clickout_price',   \n",
    "                'future_clickout_price_mean', \n",
    "                'future_clickout_price_std',\n",
    "                'future_clickout_price_diff',\n",
    "                'cur_item_count_future']\n",
    "\n",
    "procs = [FillMissing,Categorify, Normalize]\n",
    "train['is_va'] = train.row_id%5 == 0\n",
    "\n",
    "test_list = TabularList.from_df(test, path='./', cat_names=cat_names, cont_names=cont_names)\n",
    "\n",
    "data_tab = (TabularList.from_df(train, path='./', cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
    "                           .split_from_df('is_va')\n",
    "                           .label_from_df(cols='target')\n",
    "                           .add_test(test_list)\n",
    "                           .databunch(num_workers=10,bs=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "write_pkl(data_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "data_pair.to_pickle('cache/data_pair_context.pkl')\n",
    "del data_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "learn_tab = tabular_learner(data_tab, layers=[64], metrics=None, callback_fns=AUROC,#wd=0.2,\n",
    "        emb_szs = {'user_id': 16,'item_id':32,'platform':4,'city':8,'device':1,\n",
    "                   'current_filters':8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2, max_lr=slice(3e-3), callbacks=[SaveModelCallback(learn,\n",
    "        every='improvement', monitor='AUROC',name='tab_nn')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_tab.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop the output classification layer,\n",
    "learn_tab.model.layers = learn_tab.model.layers[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_tab.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <left> Binary features from metadata</left> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bin_feature = pd.read_csv('bin_itemmeta.csv')\n",
    "bin_feature.rename(columns={'index': 'item_id'}, inplace=True)\n",
    "bin_feature.drop(columns=['Unnamed: 0', 'Unnamed: 2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "item_embd_idx = 'item_embd_idx'\n",
    "\n",
    "bin_feature[item_embd_idx] = bin_feature['item_id'].apply(get_idx)\n",
    "bin_feature_cols = [c for c in bin_feature.columns if c != item_embd_idx and c != 'item_id']\n",
    "bin_feature = bin_feature[bin_feature[item_embd_idx] != 0]\n",
    "max_idx = max(id_to_index.values())\n",
    "bin_feature_matrix = np.random.rand(max_idx+1, bin_feature.shape[1]-2)\n",
    "bin_feature_matrix[bin_feature['item_embd_idx'], :] = bin_feature[bin_feature_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test equivalency\n",
    "rand_row = random.choice(range(bin_feature.shape[0]))\n",
    "embed_orig = bin_feature.iloc[rand_row][bin_feature_cols].values\n",
    "idx = bin_feature.iloc[rand_row][item_embd_idx]\n",
    "embed_matrix = bin_feature_matrix[idx, :]\n",
    "print(\"embedding matrix matched: {}\".format(np.array_equal(embed_matrix, embed_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cache/bin_feature_matrix', bin_feature_matrix)\n",
    "bin_feature_matrix = torch.from_numpy(bin_feature_matrix).float().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <left> Concate dataset </left> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetPast(Dataset):\n",
    "    def __init__(self, data): \n",
    "        self.data = data\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.76 s, sys: 10.7 s, total: 20.5 s\n",
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "context_cols = ['past_clickout_item', 'future_clickout_item']\n",
    "train_past_future_click = train[train.is_va==0][context_cols].values\n",
    "valid_past_future_click = train[train.is_va==1][context_cols].values\n",
    "test_past_future_click = test[context_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(Dataset):\n",
    "    def __init__(self, x_tab, x_pf_click, y):\n",
    "        self.x_tab = x_tab\n",
    "        self.x_pf_click = x_pf_click\n",
    "        self.y = [0] * len(x_pf_click) if not y else y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, i):\n",
    "        return (self.x_tab[i],  self.x_pf_click[i]), self.y[i]\n",
    "\n",
    "train_ds = ConcatDataset(data_tab.train_ds.x, train_past_future_click, data_tab.train_ds.y)\n",
    "valid_ds = ConcatDataset(data_tab.valid_ds.x, valid_past_future_click, data_tab.valid_ds.y)\n",
    "test_ds =  ConcatDataset(data_tab.test_ds.x, test_past_future_click, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch): \n",
    "    x, y = list(zip(*batch))\n",
    "    x_tab, x_pf_click = list(zip(*x))\n",
    "    x_cats, x_conts = zip(*[(t.cats, t.conts) for t in x_tab])\n",
    "    x_cats = torch.tensor(x_cats, dtype=torch.long)\n",
    "    x_conts = torch.tensor(x_conts, dtype=torch.float)\n",
    "    x_pf_click = torch.tensor(x_pf_click, dtype=torch.long)\n",
    "    y = torch.tensor([int(t) for t in y])\n",
    "    return ((x_cats, x_conts), x_pf_click), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "train_dl = DataLoader(train_ds, bs, collate_fn=my_collate, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, bs, collate_fn=my_collate, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, bs, collate_fn=my_collate, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_dl.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[204893,      0],\n",
       "        [520531,      0],\n",
       "        [     0,      0],\n",
       "        ...,\n",
       "        [158680,  91515],\n",
       "        [457455,      0],\n",
       "        [ 16120,  64160]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_dl=train_dl, valid_dl=valid_dl, test_dl=test_dl, device=defaults.device, \n",
    "                 collate_fn=my_collate, path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class WrapModel(nn.Module):\n",
    "    def __init__(self, mod_tab, layers, bin_feature_matrix, id_emb_matrix_idx, p=0.2):\n",
    "\n",
    "        super(WrapModel, self).__init__()\n",
    "        self.mod_tab = mod_tab\n",
    "        # this is the index of the id embedding in embeds.\n",
    "        self.bin_feature_matrix = bin_feature_matrix\n",
    "        self.id_embed = mod_tab.embeds[id_emb_matrix_idx]\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        lst_layers = []\n",
    "        activs = [nn.ReLU(inplace=True), ] * (len(layers) - 2) + [None]\n",
    "        for i in range(len(layers) - 1):\n",
    "            lst_layers += bn_drop_lin(layers[i], layers[i + 1], p, actn=activs[i])\n",
    "        self.layers = nn.Sequential(*lst_layers)\n",
    "\n",
    "    def get_cosine_similarity(self, x1, x2):\n",
    "        out = self.cos(x1, x2).unsqueeze(1)\n",
    "        out = out.detach()\n",
    "        return out\n",
    "\n",
    "    def forward(self, *x):\n",
    "        # x[0] is tab, x[0][0] is cat, x[0][0][:, 1] is item_id\n",
    "        x_cur_id = x[0][0][:, 1]\n",
    "        x_tab = self.mod_tab(*x[0])\n",
    "        x_cur_bin = self.bin_feature_matrix[x_cur_id, :]\n",
    "        x_cur_emb = self.id_embed(x_cur_id)\n",
    "\n",
    "\n",
    "        x_past_id = x[1][:, 0]\n",
    "        x_past_bin = self.bin_feature_matrix[x_past_id, :]\n",
    "        x_past_emb = self.id_embed(x_past_id)\n",
    "\n",
    "        x_future_id = x[1][:, 1]\n",
    "        x_future_bin = self.bin_feature_matrix[x_future_id, :]\n",
    "        x_future_emb = self.id_embed(x_future_id)\n",
    "\n",
    "        x_past_cur_bin_sim = self.get_cosine_similarity(x_cur_bin, x_past_bin)\n",
    "        x_past_cur_emb_sim = self.get_cosine_similarity(x_cur_emb, x_past_emb)\n",
    "\n",
    "        x_future_cur_bin_sim = self.get_cosine_similarity(x_cur_bin, x_future_bin)\n",
    "        x_future_cur_emb_sim = self.get_cosine_similarity(x_cur_emb, x_future_emb)\n",
    "\n",
    "        x_past_future_bin_sim = self.get_cosine_similarity(x_past_bin, x_future_bin)\n",
    "        x_past_future_emb_sim = self.get_cosine_similarity(x_past_emb, x_future_emb)\n",
    "\n",
    "        x = torch.cat([x_tab, x_past_cur_bin_sim, x_past_cur_emb_sim, x_future_cur_bin_sim,\n",
    "                       x_future_cur_emb_sim, x_past_future_bin_sim, x_past_future_emb_sim], dim=1)\n",
    "\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_layers = [64+6, 32, 16, 2]\n",
    "ps = [0.2]\n",
    "model = WrapModel(learn_tab.model, lin_layers, bin_feature_matrix, 1)\n",
    "learn = Learner(data, model, metrics=None, callback_fns=AUROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"trained_fastai_context_and_binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, slice(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For convenience, load everything saved before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 s, sys: 35.1 s, total: 45.2 s\n",
      "Wall time: 45.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_tab = pickle.load(open('06_28_2019_00-00-00.csv', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.04 s, sys: 3 s, total: 11 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn_tab = tabular_learner(data_tab, layers=[64], metrics=None, callback_fns=AUROC,#wd=0.2,\n",
    "        emb_szs = {'user_id': 16,'item_id':32,'platform':4,'city':8,'device':1,\n",
    "                   'current_filters':8})\n",
    "learn_tab.model.layers = learn_tab.model.layers[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 29.9 s, total: 52.2 s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_pair = pd.read_pickle('cache/data_pair_context.pkl')\n",
    "train = data_pair[data_pair.clickout_missing==0]\n",
    "test = data_pair[data_pair.clickout_missing>0]\n",
    "train['is_va'] = train.row_id%5 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 480 ms, sys: 1.89 s, total: 2.37 s\n",
      "Wall time: 7.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bin_feature_matrix =np.load('cache/bin_feature_matrix.npy')\n",
    "bin_feature_matrix = torch.from_numpy(bin_feature_matrix).float().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload model and databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 820 ms, sys: 2.31 s, total: 3.13 s\n",
      "Wall time: 9.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lin_layers = [64+6, 32, 16, 2]\n",
    "ps = [0.2]\n",
    "model = WrapModel(learn_tab.model, lin_layers, bin_feature_matrix, 1)\n",
    "learn = Learner(data, model, metrics=None, callback_fns=AUROC)\n",
    "learn = learn.load(\"trained_fastai_context_and_binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 52s, sys: 1min 34s, total: 10min 27s\n",
      "Wall time: 9min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "yp, y_valid = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 s, sys: 5.7 s, total: 16.4 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = train.loc[train['row_id']%5 == 0,['row_id','reference','item_id', 'target']].copy()\n",
    "cv['prob'] = yp.numpy()[:,1]\n",
    "cv = cv.sort_values(by=['row_id','prob'],ascending=False)\n",
    "# del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.92 s, sys: 524 ms, total: 4.45 s\n",
      "Wall time: 4.45 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "cv['rank']=cv.groupby('row_id')['prob'].rank(ascending=False) \n",
    "target_rank = cv[cv['target']==1]['rank']\n",
    "target_rank.hist(bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reciprocal_rank 0.1722, AUC 0.9266\n",
      "CPU times: user 2.9 s, sys: 1.36 s, total: 4.26 s\n",
      "Wall time: 4.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auc = roc_auc_score(y_valid.numpy().ravel(),yp.numpy()[:,1])\n",
    "mean_reciprocal_rank = (1/target_rank).mean() # get_mean_reciprocal_rank(cv)\n",
    "print('mean_reciprocal_rank %.4f, AUC %.4f'%(mean_reciprocal_rank,auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6962 364334 8026587 153460\n",
      "CPU times: user 1.7 s, sys: 1 s, total: 2.7 s\n",
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv['prob'] = yp.numpy()[:,1]\n",
    "cv['prob0'] = yp.numpy()[:,0]\n",
    "tp = sum(cv[cv['target']==1]['prob']>cv[cv['target']==1]['prob0'])\n",
    "fp = sum(cv[cv['target']==1]['prob']<=cv[cv['target']==1]['prob0'])\n",
    "tn = sum(cv[cv['target']==0]['prob']<cv[cv['target']==0]['prob0'])\n",
    "fn = sum(cv[cv['target']==0]['prob']>=cv[cv['target']==0]['prob0'])\n",
    "print(tp,fp,tn,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "yps,_ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test['target'] = yps.numpy()[:,1]\n",
    "test = test['row_id,user_id,session_id,timestamp,step,item_id,target'.split(',')]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = test.sort_values(by=['row_id','target'],ascending=False) # larger probs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sub = test[['row_id','item_id']].copy()\n",
    "sub = sub.groupby('row_id')['item_id'].apply(lambda x: ' '.join([str(i) for i in x]))\n",
    "sub = sub.to_frame()\n",
    "sub.columns = ['new_item_recommendations']\n",
    "sub = sub.reset_index()\n",
    "\n",
    "test = test.drop_duplicates(subset=['row_id'])\n",
    "sub = test.merge(sub,on='row_id',how='left')\n",
    "sub = sub[['session_id','new_item_recommendations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_sub = pd.read_csv('/datasets/trivago/data/submission_popular.csv')\n",
    "# sample_sub = pd.read_csv('../input/submission_popular.csv')\n",
    "assert sample_sub.shape[0] == sample_sub.session_id.unique().shape[0]\n",
    "sub = sample_sub.merge(sub,on='session_id',how='left')\n",
    "\n",
    "from datetime import datetime\n",
    "clock = \"{}\".format(datetime.now()).replace(' ','-').replace(':','-').split('.')[0]\n",
    "\n",
    "mask = sub.new_item_recommendations.isnull() == 0\n",
    "sub.loc[mask,'item_recommendations'] = sub.loc[mask,'new_item_recommendations']\n",
    "sub = sub.drop('new_item_recommendations',axis=1)\n",
    "out = 'fastai_%s_mrr_%.4f_auc_%.4f.csv'%(clock,mean_reciprocal_rank,auc)\n",
    "sub.to_csv(out,index=False)\n",
    "\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
